{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjYhYC9hr67q",
        "outputId": "a74d4123-0a3e-40d5-a282-625e8ec2814f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#link google colab with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first to import libraries\n",
        "from keras.layers import Input, Lambda, Dense, Flatten, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import SGD\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings   \n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "AGEbNOCkssQO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/drive/MyDrive/Data_Small2/train'\n",
        "val_data_dir = '/content/drive/MyDrive/Data_Small2/val'\n",
        "test_data_dir = '/content/drive/MyDrive/Data_Small2/test'\n",
        "img_width, img_height = 128, 128\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "tBjF7VUZzBSG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "z9b_sGzrzBQf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "        val_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_data_dir,\n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5pRHaKyzBNa",
        "outputId": "9a78fb06-a05d-471f-df9b-eae575a0b0d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2014 images belonging to 2 classes.\n",
            "Found 507 images belonging to 2 classes.\n",
            "Found 514 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
      ],
      "metadata": {
        "id": "Q9Fh1kBuzBKj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)"
      ],
      "metadata": {
        "id": "ivlmGMIWzBH7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model\n",
        "modelA = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "metadata": {
        "id": "aeGaRDgRzBA8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False "
      ],
      "metadata": {
        "id": "mC0X--IIz9RY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "modelA.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoWD-IxJz9PH",
        "outputId": "58d18dd7-3a12-40a4-c012-333c34888345"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "modelA.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // batch_size,\n",
        "        epochs=150,\n",
        "        validation_data=val_generator,\n",
        "        validation_steps=val_generator.samples // batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b-hUVi6z9MX",
        "outputId": "ed6b9013-dab1-47a2-cdc3-6dd8793e7ca2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-3446c55fad91>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  modelA.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 10s 168ms/step - loss: 0.6632 - accuracy: 0.5979 - val_loss: 0.6619 - val_accuracy: 0.5896\n",
            "Epoch 2/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.6591 - accuracy: 0.6004 - val_loss: 0.6596 - val_accuracy: 0.5875\n",
            "Epoch 3/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.6559 - accuracy: 0.5999 - val_loss: 0.6565 - val_accuracy: 0.5896\n",
            "Epoch 4/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6539 - accuracy: 0.5989 - val_loss: 0.6516 - val_accuracy: 0.5979\n",
            "Epoch 5/150\n",
            "62/62 [==============================] - 11s 170ms/step - loss: 0.6516 - accuracy: 0.5999 - val_loss: 0.6463 - val_accuracy: 0.5979\n",
            "Epoch 6/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6486 - accuracy: 0.5994 - val_loss: 0.6456 - val_accuracy: 0.5938\n",
            "Epoch 7/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.6456 - accuracy: 0.6029 - val_loss: 0.6419 - val_accuracy: 0.5979\n",
            "Epoch 8/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.6441 - accuracy: 0.6024 - val_loss: 0.6364 - val_accuracy: 0.6083\n",
            "Epoch 9/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.6425 - accuracy: 0.6024 - val_loss: 0.6392 - val_accuracy: 0.5958\n",
            "Epoch 10/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6424 - accuracy: 0.5989 - val_loss: 0.6382 - val_accuracy: 0.5938\n",
            "Epoch 11/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6393 - accuracy: 0.6004 - val_loss: 0.6332 - val_accuracy: 0.6146\n",
            "Epoch 12/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.6375 - accuracy: 0.6110 - val_loss: 0.6334 - val_accuracy: 0.5958\n",
            "Epoch 13/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.6371 - accuracy: 0.6039 - val_loss: 0.6324 - val_accuracy: 0.6083\n",
            "Epoch 14/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.6346 - accuracy: 0.6130 - val_loss: 0.6261 - val_accuracy: 0.6104\n",
            "Epoch 15/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.6338 - accuracy: 0.6105 - val_loss: 0.6294 - val_accuracy: 0.5958\n",
            "Epoch 16/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6310 - accuracy: 0.6160 - val_loss: 0.6284 - val_accuracy: 0.5958\n",
            "Epoch 17/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.6294 - accuracy: 0.6090 - val_loss: 0.6246 - val_accuracy: 0.6333\n",
            "Epoch 18/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.6282 - accuracy: 0.6297 - val_loss: 0.6170 - val_accuracy: 0.6396\n",
            "Epoch 19/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.6268 - accuracy: 0.6231 - val_loss: 0.6198 - val_accuracy: 0.6229\n",
            "Epoch 20/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.6256 - accuracy: 0.6322 - val_loss: 0.6153 - val_accuracy: 0.6375\n",
            "Epoch 21/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.6216 - accuracy: 0.6327 - val_loss: 0.6157 - val_accuracy: 0.6292\n",
            "Epoch 22/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.6223 - accuracy: 0.6372 - val_loss: 0.6125 - val_accuracy: 0.6313\n",
            "Epoch 23/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.6211 - accuracy: 0.6382 - val_loss: 0.6116 - val_accuracy: 0.6313\n",
            "Epoch 24/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.6187 - accuracy: 0.6332 - val_loss: 0.6102 - val_accuracy: 0.6208\n",
            "Epoch 25/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.6173 - accuracy: 0.6413 - val_loss: 0.6079 - val_accuracy: 0.6479\n",
            "Epoch 26/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.6157 - accuracy: 0.6413 - val_loss: 0.6103 - val_accuracy: 0.6271\n",
            "Epoch 27/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.6158 - accuracy: 0.6524 - val_loss: 0.6065 - val_accuracy: 0.6521\n",
            "Epoch 28/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6137 - accuracy: 0.6413 - val_loss: 0.6075 - val_accuracy: 0.7250\n",
            "Epoch 29/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.6121 - accuracy: 0.6635 - val_loss: 0.6039 - val_accuracy: 0.6708\n",
            "Epoch 30/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6108 - accuracy: 0.6524 - val_loss: 0.6033 - val_accuracy: 0.6313\n",
            "Epoch 31/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6096 - accuracy: 0.6504 - val_loss: 0.6030 - val_accuracy: 0.6833\n",
            "Epoch 32/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.6068 - accuracy: 0.6604 - val_loss: 0.5976 - val_accuracy: 0.6542\n",
            "Epoch 33/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.6047 - accuracy: 0.6564 - val_loss: 0.6008 - val_accuracy: 0.6396\n",
            "Epoch 34/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6074 - accuracy: 0.6549 - val_loss: 0.5942 - val_accuracy: 0.6667\n",
            "Epoch 35/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.6040 - accuracy: 0.6685 - val_loss: 0.5927 - val_accuracy: 0.6729\n",
            "Epoch 36/150\n",
            "62/62 [==============================] - 10s 167ms/step - loss: 0.6024 - accuracy: 0.6670 - val_loss: 0.5892 - val_accuracy: 0.6917\n",
            "Epoch 37/150\n",
            "62/62 [==============================] - 10s 167ms/step - loss: 0.6028 - accuracy: 0.6690 - val_loss: 0.5884 - val_accuracy: 0.7042\n",
            "Epoch 38/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5986 - accuracy: 0.6771 - val_loss: 0.5854 - val_accuracy: 0.6625\n",
            "Epoch 39/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5982 - accuracy: 0.6630 - val_loss: 0.5847 - val_accuracy: 0.7083\n",
            "Epoch 40/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5973 - accuracy: 0.6710 - val_loss: 0.5865 - val_accuracy: 0.7104\n",
            "Epoch 41/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.5955 - accuracy: 0.6776 - val_loss: 0.5826 - val_accuracy: 0.6979\n",
            "Epoch 42/150\n",
            "62/62 [==============================] - 10s 167ms/step - loss: 0.5950 - accuracy: 0.6877 - val_loss: 0.5781 - val_accuracy: 0.7188\n",
            "Epoch 43/150\n",
            "62/62 [==============================] - 10s 159ms/step - loss: 0.5929 - accuracy: 0.6710 - val_loss: 0.5784 - val_accuracy: 0.7167\n",
            "Epoch 44/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5930 - accuracy: 0.6720 - val_loss: 0.5806 - val_accuracy: 0.7063\n",
            "Epoch 45/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5914 - accuracy: 0.6882 - val_loss: 0.5794 - val_accuracy: 0.6979\n",
            "Epoch 46/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5895 - accuracy: 0.6831 - val_loss: 0.5768 - val_accuracy: 0.6854\n",
            "Epoch 47/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5868 - accuracy: 0.6872 - val_loss: 0.5721 - val_accuracy: 0.7063\n",
            "Epoch 48/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.5886 - accuracy: 0.6867 - val_loss: 0.5739 - val_accuracy: 0.7125\n",
            "Epoch 49/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5856 - accuracy: 0.6902 - val_loss: 0.5739 - val_accuracy: 0.7083\n",
            "Epoch 50/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5847 - accuracy: 0.7008 - val_loss: 0.5743 - val_accuracy: 0.6979\n",
            "Epoch 51/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5848 - accuracy: 0.6917 - val_loss: 0.5725 - val_accuracy: 0.6833\n",
            "Epoch 52/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.5835 - accuracy: 0.6927 - val_loss: 0.5689 - val_accuracy: 0.7063\n",
            "Epoch 53/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5823 - accuracy: 0.6973 - val_loss: 0.5635 - val_accuracy: 0.7271\n",
            "Epoch 54/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5806 - accuracy: 0.7013 - val_loss: 0.5671 - val_accuracy: 0.7167\n",
            "Epoch 55/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5800 - accuracy: 0.7033 - val_loss: 0.5614 - val_accuracy: 0.7312\n",
            "Epoch 56/150\n",
            "62/62 [==============================] - 11s 170ms/step - loss: 0.5788 - accuracy: 0.7109 - val_loss: 0.5608 - val_accuracy: 0.7271\n",
            "Epoch 57/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5762 - accuracy: 0.7084 - val_loss: 0.5599 - val_accuracy: 0.7188\n",
            "Epoch 58/150\n",
            "62/62 [==============================] - 10s 167ms/step - loss: 0.5761 - accuracy: 0.7109 - val_loss: 0.5609 - val_accuracy: 0.7125\n",
            "Epoch 59/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5756 - accuracy: 0.6988 - val_loss: 0.5668 - val_accuracy: 0.6896\n",
            "Epoch 60/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5733 - accuracy: 0.7074 - val_loss: 0.5569 - val_accuracy: 0.7167\n",
            "Epoch 61/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5722 - accuracy: 0.7114 - val_loss: 0.5564 - val_accuracy: 0.7271\n",
            "Epoch 62/150\n",
            "62/62 [==============================] - 10s 159ms/step - loss: 0.5723 - accuracy: 0.7185 - val_loss: 0.5533 - val_accuracy: 0.7375\n",
            "Epoch 63/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5709 - accuracy: 0.7109 - val_loss: 0.5568 - val_accuracy: 0.7312\n",
            "Epoch 64/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.5704 - accuracy: 0.7245 - val_loss: 0.5516 - val_accuracy: 0.7250\n",
            "Epoch 65/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5676 - accuracy: 0.7255 - val_loss: 0.5537 - val_accuracy: 0.7229\n",
            "Epoch 66/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5683 - accuracy: 0.7099 - val_loss: 0.5555 - val_accuracy: 0.7312\n",
            "Epoch 67/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5658 - accuracy: 0.7245 - val_loss: 0.5547 - val_accuracy: 0.7021\n",
            "Epoch 68/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5668 - accuracy: 0.7154 - val_loss: 0.5515 - val_accuracy: 0.7146\n",
            "Epoch 69/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5634 - accuracy: 0.7275 - val_loss: 0.5447 - val_accuracy: 0.7521\n",
            "Epoch 70/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.5632 - accuracy: 0.7301 - val_loss: 0.5493 - val_accuracy: 0.7437\n",
            "Epoch 71/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5614 - accuracy: 0.7265 - val_loss: 0.5445 - val_accuracy: 0.7396\n",
            "Epoch 72/150\n",
            "62/62 [==============================] - 10s 159ms/step - loss: 0.5608 - accuracy: 0.7291 - val_loss: 0.5476 - val_accuracy: 0.7437\n",
            "Epoch 73/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5614 - accuracy: 0.7260 - val_loss: 0.5397 - val_accuracy: 0.7542\n",
            "Epoch 74/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5598 - accuracy: 0.7275 - val_loss: 0.5433 - val_accuracy: 0.7500\n",
            "Epoch 75/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5597 - accuracy: 0.7281 - val_loss: 0.5452 - val_accuracy: 0.7271\n",
            "Epoch 76/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5580 - accuracy: 0.7381 - val_loss: 0.5378 - val_accuracy: 0.7396\n",
            "Epoch 77/150\n",
            "62/62 [==============================] - 10s 158ms/step - loss: 0.5578 - accuracy: 0.7215 - val_loss: 0.5411 - val_accuracy: 0.7271\n",
            "Epoch 78/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5558 - accuracy: 0.7356 - val_loss: 0.5354 - val_accuracy: 0.7417\n",
            "Epoch 79/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.5552 - accuracy: 0.7316 - val_loss: 0.5400 - val_accuracy: 0.7333\n",
            "Epoch 80/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5535 - accuracy: 0.7351 - val_loss: 0.5357 - val_accuracy: 0.7417\n",
            "Epoch 81/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5514 - accuracy: 0.7361 - val_loss: 0.5336 - val_accuracy: 0.7417\n",
            "Epoch 82/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5509 - accuracy: 0.7356 - val_loss: 0.5311 - val_accuracy: 0.7667\n",
            "Epoch 83/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5519 - accuracy: 0.7402 - val_loss: 0.5292 - val_accuracy: 0.7479\n",
            "Epoch 84/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5498 - accuracy: 0.7321 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
            "Epoch 85/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5493 - accuracy: 0.7351 - val_loss: 0.5321 - val_accuracy: 0.7542\n",
            "Epoch 86/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5485 - accuracy: 0.7397 - val_loss: 0.5314 - val_accuracy: 0.7417\n",
            "Epoch 87/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5467 - accuracy: 0.7407 - val_loss: 0.5263 - val_accuracy: 0.7542\n",
            "Epoch 88/150\n",
            "62/62 [==============================] - 10s 167ms/step - loss: 0.5475 - accuracy: 0.7386 - val_loss: 0.5230 - val_accuracy: 0.7625\n",
            "Epoch 89/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5461 - accuracy: 0.7402 - val_loss: 0.5261 - val_accuracy: 0.7625\n",
            "Epoch 90/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5442 - accuracy: 0.7412 - val_loss: 0.5261 - val_accuracy: 0.7604\n",
            "Epoch 91/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5444 - accuracy: 0.7465 - val_loss: 0.5229 - val_accuracy: 0.7604\n",
            "Epoch 92/150\n",
            "62/62 [==============================] - 10s 160ms/step - loss: 0.5439 - accuracy: 0.7402 - val_loss: 0.5191 - val_accuracy: 0.7708\n",
            "Epoch 93/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.5413 - accuracy: 0.7492 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
            "Epoch 94/150\n",
            "62/62 [==============================] - 10s 167ms/step - loss: 0.5404 - accuracy: 0.7427 - val_loss: 0.5260 - val_accuracy: 0.7354\n",
            "Epoch 95/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5402 - accuracy: 0.7518 - val_loss: 0.5228 - val_accuracy: 0.7396\n",
            "Epoch 96/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5384 - accuracy: 0.7482 - val_loss: 0.5215 - val_accuracy: 0.7437\n",
            "Epoch 97/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5378 - accuracy: 0.7457 - val_loss: 0.5259 - val_accuracy: 0.7396\n",
            "Epoch 98/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5385 - accuracy: 0.7402 - val_loss: 0.5215 - val_accuracy: 0.7375\n",
            "Epoch 99/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5375 - accuracy: 0.7548 - val_loss: 0.5137 - val_accuracy: 0.7625\n",
            "Epoch 100/150\n",
            "62/62 [==============================] - 11s 171ms/step - loss: 0.5345 - accuracy: 0.7503 - val_loss: 0.5206 - val_accuracy: 0.7458\n",
            "Epoch 101/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5319 - accuracy: 0.7548 - val_loss: 0.5104 - val_accuracy: 0.7750\n",
            "Epoch 102/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.5343 - accuracy: 0.7447 - val_loss: 0.5153 - val_accuracy: 0.7750\n",
            "Epoch 103/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5335 - accuracy: 0.7538 - val_loss: 0.5118 - val_accuracy: 0.7521\n",
            "Epoch 104/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5327 - accuracy: 0.7548 - val_loss: 0.5135 - val_accuracy: 0.7583\n",
            "Epoch 105/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5301 - accuracy: 0.7467 - val_loss: 0.5076 - val_accuracy: 0.7750\n",
            "Epoch 106/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.5288 - accuracy: 0.7543 - val_loss: 0.5086 - val_accuracy: 0.7937\n",
            "Epoch 107/150\n",
            "62/62 [==============================] - 10s 160ms/step - loss: 0.5294 - accuracy: 0.7563 - val_loss: 0.5072 - val_accuracy: 0.7479\n",
            "Epoch 108/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5288 - accuracy: 0.7563 - val_loss: 0.5081 - val_accuracy: 0.7500\n",
            "Epoch 109/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5282 - accuracy: 0.7578 - val_loss: 0.5056 - val_accuracy: 0.7563\n",
            "Epoch 110/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5276 - accuracy: 0.7508 - val_loss: 0.5047 - val_accuracy: 0.7625\n",
            "Epoch 111/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5243 - accuracy: 0.7634 - val_loss: 0.5133 - val_accuracy: 0.7458\n",
            "Epoch 112/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5248 - accuracy: 0.7598 - val_loss: 0.5034 - val_accuracy: 0.7792\n",
            "Epoch 113/150\n",
            "62/62 [==============================] - 10s 160ms/step - loss: 0.5262 - accuracy: 0.7548 - val_loss: 0.5013 - val_accuracy: 0.7667\n",
            "Epoch 114/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5246 - accuracy: 0.7624 - val_loss: 0.5028 - val_accuracy: 0.7625\n",
            "Epoch 115/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5221 - accuracy: 0.7593 - val_loss: 0.5021 - val_accuracy: 0.7521\n",
            "Epoch 116/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5222 - accuracy: 0.7608 - val_loss: 0.4966 - val_accuracy: 0.7979\n",
            "Epoch 117/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5232 - accuracy: 0.7674 - val_loss: 0.5019 - val_accuracy: 0.7771\n",
            "Epoch 118/150\n",
            "62/62 [==============================] - 11s 169ms/step - loss: 0.5220 - accuracy: 0.7558 - val_loss: 0.5045 - val_accuracy: 0.7583\n",
            "Epoch 119/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5183 - accuracy: 0.7669 - val_loss: 0.5053 - val_accuracy: 0.7542\n",
            "Epoch 120/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5186 - accuracy: 0.7603 - val_loss: 0.4980 - val_accuracy: 0.7812\n",
            "Epoch 121/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5174 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7875\n",
            "Epoch 122/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5159 - accuracy: 0.7694 - val_loss: 0.4968 - val_accuracy: 0.7458\n",
            "Epoch 123/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5171 - accuracy: 0.7654 - val_loss: 0.4963 - val_accuracy: 0.7563\n",
            "Epoch 124/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.5154 - accuracy: 0.7568 - val_loss: 0.4929 - val_accuracy: 0.7667\n",
            "Epoch 125/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5148 - accuracy: 0.7664 - val_loss: 0.4953 - val_accuracy: 0.7667\n",
            "Epoch 126/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5112 - accuracy: 0.7674 - val_loss: 0.4933 - val_accuracy: 0.7667\n",
            "Epoch 127/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5135 - accuracy: 0.7639 - val_loss: 0.4963 - val_accuracy: 0.7563\n",
            "Epoch 128/150\n",
            "62/62 [==============================] - 10s 160ms/step - loss: 0.5117 - accuracy: 0.7669 - val_loss: 0.4886 - val_accuracy: 0.7688\n",
            "Epoch 129/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.5114 - accuracy: 0.7714 - val_loss: 0.4940 - val_accuracy: 0.7667\n",
            "Epoch 130/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.5106 - accuracy: 0.7740 - val_loss: 0.4883 - val_accuracy: 0.7646\n",
            "Epoch 131/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5107 - accuracy: 0.7709 - val_loss: 0.4894 - val_accuracy: 0.7792\n",
            "Epoch 132/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.5091 - accuracy: 0.7654 - val_loss: 0.4895 - val_accuracy: 0.7875\n",
            "Epoch 133/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.5101 - accuracy: 0.7654 - val_loss: 0.4872 - val_accuracy: 0.7792\n",
            "Epoch 134/150\n",
            "62/62 [==============================] - 10s 165ms/step - loss: 0.5097 - accuracy: 0.7654 - val_loss: 0.4921 - val_accuracy: 0.7542\n",
            "Epoch 135/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5088 - accuracy: 0.7709 - val_loss: 0.4869 - val_accuracy: 0.7708\n",
            "Epoch 136/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5054 - accuracy: 0.7735 - val_loss: 0.4873 - val_accuracy: 0.8021\n",
            "Epoch 137/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.5059 - accuracy: 0.7785 - val_loss: 0.4903 - val_accuracy: 0.7500\n",
            "Epoch 138/150\n",
            "62/62 [==============================] - 10s 159ms/step - loss: 0.5052 - accuracy: 0.7755 - val_loss: 0.4849 - val_accuracy: 0.7771\n",
            "Epoch 139/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.5024 - accuracy: 0.7785 - val_loss: 0.4819 - val_accuracy: 0.8021\n",
            "Epoch 140/150\n",
            "62/62 [==============================] - 10s 163ms/step - loss: 0.5040 - accuracy: 0.7709 - val_loss: 0.4779 - val_accuracy: 0.8104\n",
            "Epoch 141/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5039 - accuracy: 0.7780 - val_loss: 0.4816 - val_accuracy: 0.7812\n",
            "Epoch 142/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5016 - accuracy: 0.7775 - val_loss: 0.4821 - val_accuracy: 0.8021\n",
            "Epoch 143/150\n",
            "62/62 [==============================] - 10s 161ms/step - loss: 0.4996 - accuracy: 0.7755 - val_loss: 0.4802 - val_accuracy: 0.8021\n",
            "Epoch 144/150\n",
            "62/62 [==============================] - 10s 164ms/step - loss: 0.5031 - accuracy: 0.7740 - val_loss: 0.4776 - val_accuracy: 0.7917\n",
            "Epoch 145/150\n",
            "62/62 [==============================] - 10s 169ms/step - loss: 0.4991 - accuracy: 0.7740 - val_loss: 0.4722 - val_accuracy: 0.8021\n",
            "Epoch 146/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.4995 - accuracy: 0.7800 - val_loss: 0.4783 - val_accuracy: 0.7792\n",
            "Epoch 147/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.4997 - accuracy: 0.7694 - val_loss: 0.4758 - val_accuracy: 0.8021\n",
            "Epoch 148/150\n",
            "62/62 [==============================] - 10s 166ms/step - loss: 0.4979 - accuracy: 0.7825 - val_loss: 0.4744 - val_accuracy: 0.7833\n",
            "Epoch 149/150\n",
            "62/62 [==============================] - 10s 168ms/step - loss: 0.4982 - accuracy: 0.7760 - val_loss: 0.4771 - val_accuracy: 0.7896\n",
            "Epoch 150/150\n",
            "62/62 [==============================] - 10s 162ms/step - loss: 0.4982 - accuracy: 0.7770 - val_loss: 0.4779 - val_accuracy: 0.8021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58f009fbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# assume that `model` is a trained machine learning model\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(modelA, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkpnCId5Yc9m",
        "outputId": "3c3581d9-e196-4e54-ad93-eadfe8c515d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
            "...layers\n",
            "......conv2d\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_1\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_10\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_11\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_12\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_2\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_3\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_4\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_5\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_6\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_7\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_8\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......conv2d_9\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......dense_1\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......global_average_pooling2d\n",
            ".........vars\n",
            "......input_layer\n",
            ".........vars\n",
            "......max_pooling2d\n",
            ".........vars\n",
            "......max_pooling2d_1\n",
            ".........vars\n",
            "......max_pooling2d_2\n",
            ".........vars\n",
            "......max_pooling2d_3\n",
            ".........vars\n",
            "......max_pooling2d_4\n",
            ".........vars\n",
            "...metrics\n",
            "......mean\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "......mean_metric_wrapper\n",
            ".........vars\n",
            "............0\n",
            "............1\n",
            "...vars\n",
            "Keras model archive saving:\n",
            "File Name                                             Modified             Size\n",
            "metadata.json                                  2023-03-24 01:09:40           64\n",
            "variables.h5                                   2023-03-24 01:09:40     61031976\n",
            "config.json                                    2023-03-24 01:09:40        11774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelA.save('/content/drive/MyDrive/models/my_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP3EPCpwlx_B",
        "outputId": "e7ca4133-1287-495a-fb36-efa13fdf0fd9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u9wXyz0lI5Pe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}